{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b14d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8c9310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RN50', 'openai'),\n",
       " ('RN50', 'yfcc15m'),\n",
       " ('RN50', 'cc12m'),\n",
       " ('RN50-quickgelu', 'openai'),\n",
       " ('RN50-quickgelu', 'yfcc15m'),\n",
       " ('RN50-quickgelu', 'cc12m'),\n",
       " ('RN101', 'openai'),\n",
       " ('RN101', 'yfcc15m'),\n",
       " ('RN101-quickgelu', 'openai'),\n",
       " ('RN101-quickgelu', 'yfcc15m'),\n",
       " ('RN50x4', 'openai'),\n",
       " ('RN50x16', 'openai'),\n",
       " ('RN50x64', 'openai'),\n",
       " ('ViT-B-32', 'openai'),\n",
       " ('ViT-B-32', 'laion400m_e31'),\n",
       " ('ViT-B-32', 'laion400m_e32'),\n",
       " ('ViT-B-32', 'laion2b_e16'),\n",
       " ('ViT-B-32', 'laion2b_s34b_b79k'),\n",
       " ('ViT-B-32', 'datacomp_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_clip_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_laion_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_image_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_text_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_basic_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'datacomp_s_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_clip_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_laion_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_image_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_text_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_basic_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_s13m_b4k'),\n",
       " ('ViT-B-32-quickgelu', 'openai'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e31'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e32'),\n",
       " ('ViT-B-16', 'openai'),\n",
       " ('ViT-B-16', 'laion400m_e31'),\n",
       " ('ViT-B-16', 'laion400m_e32'),\n",
       " ('ViT-B-16', 'laion2b_s34b_b88k'),\n",
       " ('ViT-B-16', 'datacomp_l_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_clip_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_laion_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_image_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_text_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_basic_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_s1b_b8k'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e31'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'openai'),\n",
       " ('ViT-L-14', 'laion400m_e31'),\n",
       " ('ViT-L-14', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'laion2b_s32b_b82k'),\n",
       " ('ViT-L-14', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_clip_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_laion_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_s13b_b90k'),\n",
       " ('ViT-L-14-336', 'openai'),\n",
       " ('ViT-H-14', 'laion2b_s32b_b79k'),\n",
       " ('ViT-g-14', 'laion2b_s12b_b42k'),\n",
       " ('ViT-g-14', 'laion2b_s34b_b88k'),\n",
       " ('ViT-bigG-14', 'laion2b_s39b_b160k'),\n",
       " ('roberta-ViT-B-32', 'laion2b_s12b_b32k'),\n",
       " ('xlm-roberta-base-ViT-B-32', 'laion5b_s13b_b90k'),\n",
       " ('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k'),\n",
       " ('convnext_base', 'laion400m_s13b_b51k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k_augreg'),\n",
       " ('convnext_base_w', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k_augreg'),\n",
       " ('convnext_large_d', 'laion2b_s26b_b102k_augreg'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft_soup'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_rewind'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_soup'),\n",
       " ('coca_ViT-B-32', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-B-32', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_clip.list_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5905db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, _, _ = open_clip.create_model_and_transforms('ViT-L-14', 'laion2b_s32b_b82k')\n",
    "tokenizer = open_clip.get_tokenizer('ViT-L-14')\n",
    "pre_process = T.Compose([\n",
    "                T.Resize(\n",
    "                    size=(224, 224), \n",
    "                    interpolation=T.InterpolationMode.BICUBIC,\n",
    "                    antialias=True),\n",
    "                T.ToTensor(), \n",
    "                T.Normalize(\n",
    "                    mean=(0.48145466, 0.4578275, 0.40821073), \n",
    "                    std=(0.26862954, 0.26130258, 0.27577711)\n",
    "                )\n",
    "            ])\n",
    "clip.cuda()\n",
    "clip.half()\n",
    "_ = clip.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f204db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transparency(im, bg_colour=(255, 255, 255)):\n",
    "\n",
    "    if im.mode in ('RGBA', 'LA') or (im.mode == 'P' and 'transparency' in im.info):\n",
    "        alpha = im.convert('RGBA').split()[-1]\n",
    "        bg = Image.new(\"RGB\", im.size, (255, 255, 255))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg\n",
    "    elif im.mode == 'P':\n",
    "        bg = Image.new(\"RGB\", im.size, (255, 255, 255))\n",
    "        bg.paste(im)\n",
    "        return bg\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e63a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsfw_sfw_keywords = json.load(open('./keywords.json'))\n",
    "keywords = []\n",
    "nsfw_keywords = nsfw_sfw_keywords[\"nsfw_keywords\"]\n",
    "for nsfw_keyword in nsfw_keywords:\n",
    "    keywords.extend(nsfw_keyword[\"keywords\"])\n",
    "sfw_keywords = nsfw_sfw_keywords[\"non_nsfw_keywords\"]\n",
    "for sfw_keyword in sfw_keywords:\n",
    "    keywords.extend(sfw_keyword[\"keywords\"])\n",
    "keywords = list(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605a1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keywords)\n",
    "keywords = [\"+13\", \"+18\", \"+17\", \"general audiences\", \"rated r\", \"family friendly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a028b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = \"./test_imgs/sfw/open_mounth.png\"\n",
    "image = Image.open(test_images)\n",
    "text = tokenizer(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec7414c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image = remove_transparency(image)\n",
    "    x = pre_process(image)\n",
    "    x = x.reshape(1, 3, 224, 224)\n",
    "    image_features = clip.encode_image(x.cuda())\n",
    "    text_features = clip.encode_text(text.cuda())\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    #text_probs = (image_features @ text_features.T)\n",
    "    #text_probs /= text_probs.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b713f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('+13', 0.6041147112846375), ('+18', 0.2557982802391052), ('+17', 0.13479621708393097), ('rated r', 0.004102418664842844), ('family friendly', 0.0011215388076379895), ('general audiences', 6.682948878733441e-05)]\n"
     ]
    }
   ],
   "source": [
    "prod_list = text_probs[0].tolist()\n",
    "results = [(keyword, prob) for keyword, prob in zip(keywords, prod_list)]\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38f007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
